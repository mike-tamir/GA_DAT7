{
 "metadata": {
  "name": "",
  "signature": "sha256:eb608b5650c37e74b18771d365419e066a5f30d268c9ac13e16bf4fe3a108d8d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# GA Data Science 7 (DAT7) - Lab2.1\n",
      "\n",
      "### APIs, JSON"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Last Time:\n",
      "\n",
      "- #### iPython\n",
      "- #### numpy  \n",
      "- #### Pandas\n",
      "\n",
      "#### Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Agenda\n",
      "\n",
      "1. JSON\n",
      "2. API "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. JSON"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "- What's Json? (and why do we care?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the homework data into a pandas dataset\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv(\"data/titanic-train.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# assign the first 5 rows to a variable called first\n",
      "\n",
      "first = data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use the DataFrame method to_json to transform <first> into a json object\n",
      "first.to_json()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# explore the different options in the to_json method\n",
      "first.to_json(orient = 'records')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# discussion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. APIs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- What's an API? (and why do we care?)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2 A simple web request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "\n",
      "def get_historical_prices(symbol, start_date, end_date):\n",
      "    \"\"\"\n",
      "    Get historical prices for the given ticker symbol.\n",
      "    Date format is 'YYYYMMDD'\n",
      "    \n",
      "    Returns a json list.\n",
      "    \"\"\"\n",
      "    url = 'http://ichart.yahoo.com/table.csv?s=%s&' % symbol + \\\n",
      "          'd=%s&' % str(int(end_date[4:6]) - 1) + \\\n",
      "          'e=%s&' % str(int(end_date[6:8])) + \\\n",
      "          'f=%s&' % str(int(end_date[0:4])) + \\\n",
      "          'g=d&' + \\\n",
      "          'a=%s&' % str(int(start_date[4:6]) - 1) + \\\n",
      "          'b=%s&' % str(int(start_date[6:8])) + \\\n",
      "          'c=%s&' % str(int(start_date[0:4])) + \\\n",
      "          'ignore=.csv'\n",
      "    days = urllib.urlopen(url).readlines()\n",
      "    data = [day[:-2].split(',') for day in days]\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_historical_prices('GOOG', '20140101', '20140106')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obtain the prices of Yahoo for the past month and insert them in a Pandas Dataframe\n",
      "\n",
      "prices =get_historical_prices('YHOO', '20140217', '20140317')\n",
      "\n",
      "df = pd.DataFrame(prices[1:], columns= prices[0], dtype=int).set_index('Date')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use the DataFrame method plot() to plot the Open, High, Low, Close curves\n",
      "\n",
      "df.Open[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Twitter API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Twitter has no less than 10 python libraries. We'll be using Python Twitter Tools because it's what's used in Mining the Social Web."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "#### Some services (like Twitter) have released Python libraries of their own to make using their API even easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CONSUMER_KEY = 'kU89M3iTVbkNhnA7b1WD9A'\n",
      "CONSUMER_SECRET ='E2erSrX5DeUByOzm2Rn4uI1SsXI2v7UTvWSDe4sDs'\n",
      "OAUTH_TOKEN = '54150531-lrpWlsun1FSq4zU81fFK03UFwLZPAfOYSr3zzY68T'\n",
      "OAUTH_TOKEN_SECRET = '8JzJx1kPv3l6rq4IBFgPZYyUloMzcPKr2r7SrBstCmiz6'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, \n",
      "                           OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY,\n",
      "                           CONSUMER_SECRET)\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "#### Using a library like this, we don't even need to specify the URL (that's handled internally)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Using a library like this, it's easy to do something like search for tweets mentioning `#bigdata`  \n",
      "\n",
      "The results are transformed into a Python object (which in this case is a thin wrapper around a `dict`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigdata = twitter_api.search.tweets(q='#bigdata', count=5)\n",
      "type(bigdata)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for status in bigdata['statuses']:\n",
      "    print status.get('text')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Twitter lab\n",
      "[http://tinyurl.com/GAtwitterlab](http://nbviewer.ipython.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%201%20-%20Mining%20Twitter.ipynb) up through Exercise 5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Useful links:\n",
      "\n",
      "[Mining the Social Web](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CONSUMER_KEY = 'kU89M3iTVbkNhnA7b1WD9A'\n",
      "CONSUMER_SECRET ='E2erSrX5DeUByOzm2Rn4uI1SsXI2v7UTvWSDe4sDs'\n",
      "OAUTH_TOKEN = '54150531-lrpWlsun1FSq4zU81fFK03UFwLZPAfOYSr3zzY68T'\n",
      "OAUTH_TOKEN_SECRET = '8JzJx1kPv3l6rq4IBFgPZYyUloMzcPKr2r7SrBstCmiz6'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "# Nothing to see by displaying twitter_api except that it's now a\n",
      "# defined variable\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
      "# http://developer.yahoo.com/geo/geoplanet/\n",
      "\n",
      "WORLD_WOE_ID = 1\n",
      "US_WOE_ID = 23424977\n",
      "\n",
      "# Prefix ID with the underscore for query string parameterization.\n",
      "# Without the underscore, the twitter package appends the ID value\n",
      "# to the URL itself as a special case keyword argument.\n",
      "\n",
      "world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID)\n",
      "us_trends = twitter_api.trends.place(_id=US_WOE_ID)\n",
      "\n",
      "print world_trends\n",
      "print\n",
      "print us_trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "print json.dumps(world_trends, indent=1)\n",
      "print\n",
      "print json.dumps(us_trends, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "world_trends_set = set([trend['name'] \n",
      "                        for trend in world_trends[0]['trends']])\n",
      "\n",
      "us_trends_set = set([trend['name'] \n",
      "                     for trend in us_trends[0]['trends']]) \n",
      "\n",
      "common_trends = world_trends_set.intersection(us_trends_set)\n",
      "\n",
      "print common_trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# XXX: Set this variable to a trending topic, \n",
      "# or anything else for that matter. The example query below\n",
      "# was a trending topic when this content was being developed\n",
      "# and is used throughout the remainder of this chapter.\n",
      "\n",
      "q = '#DataScience' \n",
      "\n",
      "count = 100\n",
      "\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
      "\n",
      "search_results = twitter_api.search.tweets(q=q, count=count)\n",
      "\n",
      "statuses = search_results['statuses']\n",
      "\n",
      "\n",
      "# Iterate through 5 more batches of results by following the cursor\n",
      "\n",
      "for _ in range(5):\n",
      "    print \"Length of statuses\", len(statuses)\n",
      "    try:\n",
      "        next_results = search_results['search_metadata']['next_results']\n",
      "    except KeyError, e: # No more results when next_results doesn't exist\n",
      "        break\n",
      "        \n",
      "    # Create a dictionary from next_results, which has the following form:\n",
      "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
      "    kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n",
      "    \n",
      "    search_results = twitter_api.search.tweets(**kwargs)\n",
      "    statuses += search_results['statuses']\n",
      "\n",
      "# Show one sample search result by slicing the list...\n",
      "print json.dumps(statuses[0], indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "status_texts = [ status['text'] \n",
      "                 for status in statuses ]\n",
      "\n",
      "screen_names = [ user_mention['screen_name'] \n",
      "                 for status in statuses\n",
      "                     for user_mention in status['entities']['user_mentions'] ]\n",
      "\n",
      "hashtags = [ hashtag['text'] \n",
      "             for status in statuses\n",
      "                 for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "# Compute a collection of all words from all tweets\n",
      "words = [ w \n",
      "          for t in status_texts \n",
      "              for w in t.split() ]\n",
      "\n",
      "# Explore the first 5 items for each...\n",
      "\n",
      "print json.dumps(status_texts[0:5], indent=1)\n",
      "print json.dumps(screen_names[0:5], indent=1) \n",
      "print json.dumps(hashtags[0:5], indent=1)\n",
      "print json.dumps(words[0:5], indent=1)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "for item in [words, screen_names, hashtags]:\n",
      "    c = Counter(item)\n",
      "    print c.most_common()[:10] # top 10\n",
      "    print\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}