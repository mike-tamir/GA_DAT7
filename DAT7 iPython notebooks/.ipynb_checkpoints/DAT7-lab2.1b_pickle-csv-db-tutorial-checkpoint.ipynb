{
 "metadata": {
  "name": "",
  "signature": "sha256:c6fbe93ee38ce58b5445eacb53aa7190c3170b81b9684f4fe4bfeb1f8433e962"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GA Data Science 7 (DAT7) - Persistent Storage\n",
      "## json, pickle, csv, databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### JSON / semi-structured data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data fetching, parsing, and storage\n",
      "import urllib2\n",
      "import json\n",
      "\n",
      "url = 'https://www.govtrack.us/api/v2/vote/1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fetch_json(url):\n",
      "    \"\"\" Fetch a json file / object from a url and convert to a python dict\n",
      "\n",
      "    Args:\n",
      "        url:  url of the json object\n",
      "\n",
      "    Returns:\n",
      "        data:  python dict containing fetched data\n",
      "\n",
      "    \"\"\"\n",
      "    req = urllib2.Request(url, None, {'user-agent': 'syncstream/vimeo'})\n",
      "    opener = urllib2.build_opener()\n",
      "    f = opener.open(req)\n",
      "    data = json.load(f)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = fetch_json(url)\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### json / dict to pickle\n",
      "\n",
      "Great - we now have our data in a convenient python dictionary!  But how can we save this to a file for later?  `pickle` it!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "# import pickle as pickle\n",
      "\n",
      "filename = 'data.pickle'\n",
      "pickle.dump(data, open(filename, \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check in your filesystem for the new file.\n",
      "\n",
      "Now let's load it back into memory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data2 = pickle.load( open( filename, \"rb\" ) )\n",
      "data2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note:  When using `pickle` on very large data structures you may want to specify a binary storage format.  See the documentation: https://docs.python.org/2/library/pickle.html "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Row-Column data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load some csv data into a pandas dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv(\"data/heart_disease.csv\")\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### pandas dataframe to pickle\n",
      "\n",
      "Suppose you make perform some operations on the data, cleaning up NaNs, adding columns, etc., and then want to save it for later.  Let's try pickling the dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = 'df.pickle'\n",
      "pickle.dump(df, open(filename, \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's load it back into memory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = pickle.load( open( filename, \"rb\" ) )\n",
      "df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that `pickle` can be used for dataframes also, but for column-structured data like this we can use other storage formats as well - e.g. csv and sql."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### pandas dataframe to csv\n",
      "`pandas` has a built-in convenience function for saving a dataframe to a .csv file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = \"df2.csv\"\n",
      "df2.to_csv(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check for the new file in the filesystem.\n",
      "\n",
      "Now let's load it back in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df3 = pd.read_csv(\"df2.csv\")\n",
      "df3.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: Be careful when converting between dataframes and .csv - depending on the arguments the conversion may involve value and/or datatype substitution.  For example, `to_csv()` uses an empty string in the csv to represent missing values.   \n",
      "\n",
      "Notice that in the save and reload we got an *Unnamed* column with our row ids.  \n",
      "\n",
      "See the documentation for more info:\n",
      "\n",
      "ref: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### pandas dataframe to SQL\n",
      "\n",
      "Recall that structured, table-oriented data is also a good fit for storing as SQL.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "import pandas.io.sql as psql\n",
      "\n",
      "sqlite_db = 'df.sqlite'\n",
      "conn = sqlite3.connect(sqlite_db)   # creates the database if it does not already exist\n",
      "# c = conn.cursor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In your filesystem there should now be a new sqlite file.  `pandas` has a convenience function to write dataframe contents to sql.\n",
      "\n",
      "ref: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html\n",
      "\n",
      "Notice that `to_sql` can create a table if it does not already exist."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2.to_sql('table1', conn, if_exists=\"append\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at the database using our Firefox tool.  Things look pretty good, except there is no Primary Key (which is often useful).  One way to add this would be to add an 'id' column to the dataframe, then re-write the table.  (or just perform this step first)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2['id'] = df2.index\n",
      "df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2.to_sql('table1', conn, if_exists=\"replace\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now there is an `id` column in our database with unique values, but it is not set as a PRIMARY KEY as far as sqlite is concerned.  If you need a real PRIMARY KEY, you may want to manually create the table columns first, with one of them set as the PRIMARY KEY."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psql.read_frame(\"SELECT * FROM table1 WHERE cp = 4\", conn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note:  An alternative would be to modify the pandas `to_sql` code, e.g. to take a column name as an argument that you want to use as a PRIMARY KEY.  This exercise is left to the reader.  :-)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}